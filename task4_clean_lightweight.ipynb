{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b22nZ6NdCclI",
    "outputId": "e7ad81de-8947-454c-be68-cdddc3f64d06"
   },
   "outputs": [],
   "source": [
    "# üì¶ Install HuggingFace Transformers library\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "0dc31f6c3c164e90b3a37ac5331eab90",
      "41befa495dee43a38c37e8f9155ed769",
      "5f765516dd704d1b95f30247cc90ef37",
      "df959201d89243b7a68fee274adadee2",
      "e63d895036494dbc9033fd22857a75a4",
      "0515069ba81a477582f43b6a3159c314",
      "2c966172f3dc4770aa910201cac51f14",
      "04c451f4010e43f2b39b379c29d0453b",
      "3ab78add020742c99035435faa1c4b69",
      "927057614fbe4faeadd025a90ca938dc",
      "5e3f12152b6e4e199fe83c7a51ffdbb7",
      "8952a40656c54a8283149ea293c55991",
      "62c68865ee514cbaa5aca7a383532315",
      "91f6bcb46c664b65ae6617dba9b2cb8b",
      "4a88f7d32d50480ea5509d7e41d25608",
      "aa2225a55fbd4b2ca3632f74a030b7f8",
      "19862b84ab864033a2b3b0b9e864386e",
      "210fbaba42d940be84b31d17ab4f526e",
      "01e07c5ea592439488a568ab7e48699d",
      "828b42fc9bf7434c8daff2888f86bb68",
      "cbb77ae0e7a342489d75983b26d2699a",
      "c8dedd7e0a254204bc4d1f9b340afbd6",
      "99bafee2c2d04ed8b72b7c2483e5ae81",
      "8181f3fe54bf413d9c88c47c49830ca1",
      "e32285a011de43dea70aa4a4fd349cba",
      "e9dd0853f57b41c582e6067a13842150",
      "4a1bc68d5f354a57b52b703eefc914e6",
      "71b0c2acc018425d96b190a5c04e8e33",
      "e809813a55c14c9fb7ca5c188ffaccd4",
      "76c32a4ab6744596a0ceb689906799dc",
      "75002c525f7c400d84e277e79509a54a",
      "d03990a48d724b9fbdb953910f3c3fcb",
      "4aa4286db1e74f2398e3d99f5a4f4f05",
      "cd6c75c9df7d43cab57a8c4471274585",
      "c3b82183118f4336a626c5d717a00a71",
      "206e092d0de8431ca13cec098d52fa16",
      "d085b8ed1ab6456fb1b862ae5b41823b",
      "915553eab56741edb3e3ed58a1461d11",
      "1bb1889e5a36448b958037651d1701d8",
      "8e1d4dd470974b1fbfda4e4add0b35a4",
      "a993fc9097674f15923f1a0ec918fb7e",
      "d4464a9c389a4c218763842da34a4de3",
      "106dd730091c4b9f9b1a9b7fc71e6d92",
      "a6f43385097d4a92b2709452df9903f1",
      "0c8f6f76f2db4068961af9c41c5ed1c0",
      "0fb89a13f2854304bd5ff71f5cae50ad",
      "3b9994e7e62b4794a1ea6e4b51e616eb",
      "96091890f6f1438da9603263dadaeb1c",
      "d651c7dcbd3e445eb0cdaa40d20374ae",
      "f851668c38904f4aa43fcfcc36ccf32e",
      "098c6663b8fb42ebb34cc5f7394cac6f",
      "38e29735bbe847cf89f1ab03b5719bfb",
      "2aaa6ee85a914f0fbe7205c2d6f6939a",
      "fc6eb050df2946898390b6f33ef474ff",
      "ebe3bec2b2ed48b9962682a3343b0881",
      "62281c41648e4b568761581d3bc97f01",
      "6d58a4a170f0451cbd1a7f7c5219dbd0",
      "58e66aae55cd49d0a0a02b47e6541a69",
      "589b347166d94e83acdab06df8bea384",
      "0c0c852d82ae40749611c252f6853962",
      "34676f7010f54b19a75d2d9dd85ec1f9",
      "a78df0d7add44812a8264284086c4832",
      "abdeefb0e849402b900edc251f8a958f",
      "70ab071b654c477ab47817ff4f87aea9",
      "170aefa5bf7a4683a75eeeb1d85bf90d",
      "b32a4362524848a8bbb2686b9be1c75b",
      "55b8083d883f4770b6ff922209030dcd",
      "07275ecd6d8e4e29bb6f764ed3feb675",
      "15d24adbabed437c98175709def3f257",
      "cc86a8edac944a5cb6269e3f57a0e551",
      "44bc60bbd7154332b44f2c7f30b09173",
      "c0630e0fd77843c7bf03b8504c09beea",
      "e6e6efb192cc49249fffde9390b889b2",
      "2a6a54eacf12455aa76a6e1877367df8",
      "163260bb7b994a0aa00c4e35375ded57",
      "2e37c0d2bb474335b3660143dc410dde",
      "9d0ddae1eece477e8e9c1b1b128d273b"
     ]
    },
    "id": "TPdtlPRFCuWh",
    "outputId": "7d4bbdc2-3a1b-4230-d44d-8a7105e1ea7e"
   },
   "outputs": [],
   "source": [
    "# üì• Import GPT2 model and tokenizer from transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "# üß† Choose the pre-trained GPT-2 model\n",
    "model_name = \"gpt2\"\n",
    "# üßæ Load the tokenizer for GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# üìä Load the GPT-2 model with language modeling head\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFXig4xhC0M0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ‚ú® Define a function to generate text from a given prompt\n",
    "def generate_text(prompt, max_length=150):\n",
    "    # Encode input prompt\n",
    "# üî° Encode the input prompt to token IDs\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate output from model\n",
    "# üîÆ Generate output tokens using GPT-2 model\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode and return text\n",
    "# üìù Decode the output tokens back into readable text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uK7Ye0ilDC1f",
    "outputId": "8d84c2b0-82df-4817-e4d9-9f9a40b531f0"
   },
   "outputs": [],
   "source": [
    "# Example prompt\n",
    "# üßæ Provide a prompt or topic to generate text about\n",
    "prompt = \"The future of artificial intelligence in healthcare is\"\n",
    "\n",
    "# Generate and print text\n",
    "output = generate_text(prompt)\n",
    "# üìÉ Print the generated text\n",
    "print(\"üìù Generated Text:\\n\")\n",
    "# üìÉ Print the generated text\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
