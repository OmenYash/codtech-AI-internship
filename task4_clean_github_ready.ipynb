{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b22nZ6NdCclI",
    "outputId": "e7ad81de-8947-454c-be68-cdddc3f64d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Install HuggingFace Transformers library\n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "0dc31f6c3c164e90b3a37ac5331eab90",
      "41befa495dee43a38c37e8f9155ed769",
      "5f765516dd704d1b95f30247cc90ef37",
      "df959201d89243b7a68fee274adadee2",
      "e63d895036494dbc9033fd22857a75a4",
      "0515069ba81a477582f43b6a3159c314",
      "2c966172f3dc4770aa910201cac51f14",
      "04c451f4010e43f2b39b379c29d0453b",
      "3ab78add020742c99035435faa1c4b69",
      "927057614fbe4faeadd025a90ca938dc",
      "5e3f12152b6e4e199fe83c7a51ffdbb7",
      "8952a40656c54a8283149ea293c55991",
      "62c68865ee514cbaa5aca7a383532315",
      "91f6bcb46c664b65ae6617dba9b2cb8b",
      "4a88f7d32d50480ea5509d7e41d25608",
      "aa2225a55fbd4b2ca3632f74a030b7f8",
      "19862b84ab864033a2b3b0b9e864386e",
      "210fbaba42d940be84b31d17ab4f526e",
      "01e07c5ea592439488a568ab7e48699d",
      "828b42fc9bf7434c8daff2888f86bb68",
      "cbb77ae0e7a342489d75983b26d2699a",
      "c8dedd7e0a254204bc4d1f9b340afbd6",
      "99bafee2c2d04ed8b72b7c2483e5ae81",
      "8181f3fe54bf413d9c88c47c49830ca1",
      "e32285a011de43dea70aa4a4fd349cba",
      "e9dd0853f57b41c582e6067a13842150",
      "4a1bc68d5f354a57b52b703eefc914e6",
      "71b0c2acc018425d96b190a5c04e8e33",
      "e809813a55c14c9fb7ca5c188ffaccd4",
      "76c32a4ab6744596a0ceb689906799dc",
      "75002c525f7c400d84e277e79509a54a",
      "d03990a48d724b9fbdb953910f3c3fcb",
      "4aa4286db1e74f2398e3d99f5a4f4f05",
      "cd6c75c9df7d43cab57a8c4471274585",
      "c3b82183118f4336a626c5d717a00a71",
      "206e092d0de8431ca13cec098d52fa16",
      "d085b8ed1ab6456fb1b862ae5b41823b",
      "915553eab56741edb3e3ed58a1461d11",
      "1bb1889e5a36448b958037651d1701d8",
      "8e1d4dd470974b1fbfda4e4add0b35a4",
      "a993fc9097674f15923f1a0ec918fb7e",
      "d4464a9c389a4c218763842da34a4de3",
      "106dd730091c4b9f9b1a9b7fc71e6d92",
      "a6f43385097d4a92b2709452df9903f1",
      "0c8f6f76f2db4068961af9c41c5ed1c0",
      "0fb89a13f2854304bd5ff71f5cae50ad",
      "3b9994e7e62b4794a1ea6e4b51e616eb",
      "96091890f6f1438da9603263dadaeb1c",
      "d651c7dcbd3e445eb0cdaa40d20374ae",
      "f851668c38904f4aa43fcfcc36ccf32e",
      "098c6663b8fb42ebb34cc5f7394cac6f",
      "38e29735bbe847cf89f1ab03b5719bfb",
      "2aaa6ee85a914f0fbe7205c2d6f6939a",
      "fc6eb050df2946898390b6f33ef474ff",
      "ebe3bec2b2ed48b9962682a3343b0881",
      "62281c41648e4b568761581d3bc97f01",
      "6d58a4a170f0451cbd1a7f7c5219dbd0",
      "58e66aae55cd49d0a0a02b47e6541a69",
      "589b347166d94e83acdab06df8bea384",
      "0c0c852d82ae40749611c252f6853962",
      "34676f7010f54b19a75d2d9dd85ec1f9",
      "a78df0d7add44812a8264284086c4832",
      "abdeefb0e849402b900edc251f8a958f",
      "70ab071b654c477ab47817ff4f87aea9",
      "170aefa5bf7a4683a75eeeb1d85bf90d",
      "b32a4362524848a8bbb2686b9be1c75b",
      "55b8083d883f4770b6ff922209030dcd",
      "07275ecd6d8e4e29bb6f764ed3feb675",
      "15d24adbabed437c98175709def3f257",
      "cc86a8edac944a5cb6269e3f57a0e551",
      "44bc60bbd7154332b44f2c7f30b09173",
      "c0630e0fd77843c7bf03b8504c09beea",
      "e6e6efb192cc49249fffde9390b889b2",
      "2a6a54eacf12455aa76a6e1877367df8",
      "163260bb7b994a0aa00c4e35375ded57",
      "2e37c0d2bb474335b3660143dc410dde",
      "9d0ddae1eece477e8e9c1b1b128d273b"
     ]
    },
    "id": "TPdtlPRFCuWh",
    "outputId": "7d4bbdc2-3a1b-4230-d44d-8a7105e1ea7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc31f6c3c164e90b3a37ac5331eab90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8952a40656c54a8283149ea293c55991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bafee2c2d04ed8b72b7c2483e5ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6c75c9df7d43cab57a8c4471274585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8f6f76f2db4068961af9c41c5ed1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62281c41648e4b568761581d3bc97f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b8083d883f4770b6ff922209030dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ðŸ“¥ Import GPT2 model and tokenizer from transformers\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "# ðŸ§  Choose the pre-trained GPT-2 model\n",
    "model_name = \"gpt2\"\n",
    "# ðŸ§¾ Load the tokenizer for GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# ðŸ“Š Load the GPT-2 model with language modeling head\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pFXig4xhC0M0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# âœ¨ Define a function to generate text from a given prompt\n",
    "def generate_text(prompt, max_length=150):\n",
    "    # Encode input prompt\n",
    "# ðŸ”¡ Encode the input prompt to token IDs\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate output from model\n",
    "# ðŸ”® Generate output tokens using GPT-2 model\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode and return text\n",
    "# ðŸ“ Decode the output tokens back into readable text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uK7Ye0ilDC1f",
    "outputId": "8d84c2b0-82df-4817-e4d9-9f9a40b531f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Generated Text:\n",
      "\n",
      "The future of artificial intelligence in healthcare is now a question of how far we can go in this direction. If we're going to reach the level of technological breakthroughs that will make healthcare possible, we have to get there faster than the average person could go to a doctor. It's not that we should give up on AI, it's that the future is already there.\n",
      "\n",
      "Citing the research of Professor Stephen Hawking, the AI revolution is poised to transform healthcare. That's why in the last couple of years, some of the biggest companies and organizations around the world have come together to raise their game. They're bringing in huge amounts of funding, they're investing billions in AI and they have the ability to control and make use of it\n"
     ]
    }
   ],
   "source": [
    "# Example prompt\n",
    "# ðŸ§¾ Provide a prompt or topic to generate text about\n",
    "prompt = \"The future of artificial intelligence in healthcare is\"\n",
    "\n",
    "# Generate and print text\n",
    "output = generate_text(prompt)\n",
    "# ðŸ“ƒ Print the generated text\n",
    "print(\"ðŸ“ Generated Text:\\n\")\n",
    "# ðŸ“ƒ Print the generated text\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
